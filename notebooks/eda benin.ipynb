{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22491a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Importing necessary libraries for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd46fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import missingno as msno\n",
    " \n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85b0782",
   "metadata": {},
   "source": [
    "MoonLight Energy Solutions aims to develop a strategic approach to significantly enhance its operational efficiency and sustainability through targeted solar investments. As an Analytics Engineer at MoonLight Energy Solutions, the task is to perform a quick analysis of an environmental measurement provided by the engineering team and translate the observation as a strategy report. the analysis should focus on identifying key trends and learn valuable insights that will support your data-driven case - the recommendation based on the statistical analysis and EDA.  In particular, the analysis and recommendation must present a strategy focusing on identifying high-potential regions for solar installation that align with the company's long-term sustainability goals. the report should provide an insight to help realize the overarching objectives of MoonLight Energy Solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ae6939",
   "metadata": {},
   "source": [
    "datasets  sources.\n",
    "    -data source from: https://energydata.info/dataset/?q=Solar+Radiation+Measurement&vocab_regions=AFR\n",
    "    -data structure and variable descriptions.\n",
    "     Each row in the data contains the values for solar radiation, air temperature, relative humidity, barometric pressure, precipitation, wind speed, and wind direction, cleaned and soiled radiance sensor (soiling measurement) and cleaning events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9a8a03",
   "metadata": {},
   "source": [
    "Describe data structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a67f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'C:/Users/sifra/Downloads/data/data/sierraleone_bumbuna.csv'  \n",
    "try:\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(data)\n",
    "    print(\"Dataset loaded successfully. Shape:\", df.shape)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {data} was not found. Please provide the correct file path.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV file: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3711ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700789fb",
   "metadata": {},
   "source": [
    "Data Shape: (525600, 19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb5717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 10 rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e45aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Last 5 rows of the dataset:\")\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f8cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data information\n",
    "print(\"\\nData Informtion:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe()) # for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b5fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for categorical or boolean columns\n",
    "print(df.describe(include=['object', 'category', 'bool']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6de855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = []  \n",
    "categorical_columns = [] \n",
    "\n",
    "\n",
    "if not numerical_columns:\n",
    "    numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "if not categorical_columns:\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"Numerical columns:\", numerical_columns)\n",
    "print(\"Categorical columns:\", categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c7d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0570a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute numerical columns using mean\n",
    "for col in numerical_columns:\n",
    "    if df[col].isnull().any():\n",
    "        df[col] = df[col].fillna(df[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6252b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    if df[col].isnull().any():\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "print(\"\\nMissing values after imputation:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove or Correct Outliers (for numerical columns)\n",
    "if numerical_columns:\n",
    "    # Identify outliers using z-score\n",
    "    z_scores = np.abs(stats.zscore(df[numerical_columns]))\n",
    "    threshold = 3\n",
    "    outliers = (z_scores > threshold).any(axis=1)\n",
    "    print(\"\\nOutlier rows (z-score):\\n\", df[outliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930effb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "df = df[~outliers].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9cee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize Data\n",
    "# Convert categorical text to consistent format (lowercase)\n",
    "for col in categorical_columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b97521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize numerical columns using StandardScaler\n",
    "if numerical_columns:\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18594c6",
   "metadata": {},
   "source": [
    "Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c3ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/sifra/Downloads/data/data/sierraleone_bumbuna.csv\")  # Fix path if needed\n",
    "print(\"\\nNumber of Duplicate Rows:\", data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Duplicates\n",
    "print(\"\\nDuplicate rows before removal:\", df.duplicated().sum())\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "print(\"Duplicate rows after removal:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250c7d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Categorical Variables\n",
    "# Since 'Timestamp' is the only categorical column, do not one-hot encode it.\n",
    "# Instead, extract useful time features.\n",
    "\n",
    "if 'Timestamp' in df.columns:\n",
    "    # Convert to datetime\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
    "    # Extract features\n",
    "    df['year'] = df['Timestamp'].dt.year\n",
    "    df['month'] = df['Timestamp'].dt.month\n",
    "    df['day'] = df['Timestamp'].dt.day\n",
    "    df['hour'] = df['Timestamp'].dt.hour\n",
    "    df['minute'] = df['Timestamp'].dt.minute\n",
    "    # Optionally drop the original column if not needed\n",
    "    # df = df.drop('Timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5735a99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the cleaned dataset\n",
    "print(\"\\nCleaned Dataset:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ef319",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCleaned Dataset:\\n\", df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6147bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save cleaned dataset to a new CSV file\n",
    "output_file = 'C:/Users/sifra/Downloads/data/data/sierraleon_clean.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\nCleaned dataset saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35fccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'C:/Users/sifra/Downloads/data/data/sierraleon_clean.csv'  \n",
    "\n",
    "try:\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(data)\n",
    "    print(\"Dataset loaded successfully. Shape:\", df.shape)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {data} was not found. Please provide the correct file path.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV file: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ae660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"GHI\", data=df)\n",
    "# Customize the plot\n",
    "plt.title(\"GHI Distribution\")\n",
    "# plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels if needed\n",
    "plt.tight_layout()  # Adjust layout to prevent label cutoff\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571ebbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"DHI\", data=df)\n",
    "# Customize the plot\n",
    "plt.title(\"DHI Distribution\")\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels if needed\n",
    "plt.tight_layout()  # Adjust layout to prevent label cutoff\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b336cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Tamb\", data=df)\n",
    "# Customize the plot\n",
    "plt.title(\"Tamb Distribution\")\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels if needed\n",
    "plt.tight_layout()  # Adjust layout to prevent label cutoff\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
